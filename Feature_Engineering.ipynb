{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering\n"
      ],
      "metadata": {
        "id": "APnDNKHURJPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is a parameter?**\n",
        "- A parameter is a value that describes a specific characteristic of an entire population, such as the average (mean), total, or percentage. It is usually a fixed number, but it is often unknown because we rarely have data from the whole population. For example, the average height of all adults in a country is a parameter. Since collecting data from every person is difficult, we use a sample and calculate statistics to estimate the population parameter."
      ],
      "metadata": {
        "id": "adjM5nQqRNPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.What is correlation?**\n",
        " - Correlation is a statistical measure that describes the strength and direction of a relationship between two variables. When two variables tend to increase or decrease together, they have a positive correlation. If one increases while the other decreases, they have a negative correlation. If there is no consistent pattern, the correlation is close to zero. Correlation is commonly measured using the correlation coefficient, which ranges from -1 to 1. A value close to 1 means a strong positive relationship, close to -1 means a strong negative relationship, and around 0 means little or no relationship.\n",
        "\n"
      ],
      "metadata": {
        "id": "mKXV4rSmRvfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.What does negative correlation mean?**\n",
        "- Negative correlation means that as one variable increases, the other tends to decrease, and vice versa. In other words, the two variables move in opposite directions. This relationship is represented by a correlation coefficient between -1 and 0. A value close to -1 indicates a strong negative correlation, while a value closer to 0 means a weaker relationship."
      ],
      "metadata": {
        "id": "6ZVgERA7b9W3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Define Machine Learning. What are the main components in Machine Learning?**\n",
        "- Machine Learning (ML) is a branch of artificial intelligence (AI) that enables computers to learn from data and make decisions or predictions without being explicitly programmed. Instead of following hard-coded instructions, a machine learning model improves its performance by identifying patterns in the data.\n",
        "- **Main Components of Machine Learning:**\n",
        " - **Data**: The raw information used to train the model. It can be structured (like tables) or unstructured (like images or text).\n",
        "\n",
        " - **Features**: The individual measurable properties or characteristics used as input to the model.\n",
        "\n",
        " - **Model**: The mathematical algorithm that maps inputs (features) to outputs (predictions or decisions).\n",
        "\n",
        " - **Training**: The process where the model learns patterns from the input data by adjusting its internal parameters.\n",
        "\n",
        " - **Loss Function**: A measure of how far off the model’s predictions are from the actual outcomes. It guides the learning process.\n",
        "\n",
        " - **Optimizer**: An algorithm (like gradient descent) that updates the model parameters to minimize the loss function.\n",
        "\n",
        " - **Evaluation**: Techniques (like accuracy, precision, or mean squared error) used to assess how well the model performs on new or unseen data.\n",
        "\n",
        " - **Prediction/Inference**: Once trained, the model can make predictions or decisions using new data."
      ],
      "metadata": {
        "id": "XsrIsYHxSfUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. How does loss value help in determining whether the model is good or not?**\n",
        "- The loss value helps determine how well a machine learning model is performing by measuring the difference between the model's predictions and the actual correct values. A low loss value means the model's predictions are close to the true results, which is a sign that the model is learning well. A high loss value indicates the model is making large errors and may need improvement. During training, the goal is to reduce the loss value so the model becomes more accurate. In simple terms, the loss value acts like a score showing how \"wrong\" the model is—the lower, the better."
      ],
      "metadata": {
        "id": "rhjy6LqiTfXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What are continuous and categorical variables?**\n",
        "- Continuous and categorical variables are two types of data used to describe different kinds of information. **Continuous variables** are numbers that can take any value within a range, such as height, weight, or temperature. These values can include decimals and are usually measured. On the other hand, **categorical variables** represent groups or categories, like colors, types of food, or names of cities. They describe qualities or labels rather than numbers. In simple terms, continuous variables deal with quantities, while categorical variables deal with categories or labels."
      ],
      "metadata": {
        "id": "mxIjgCw5TqcW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.How do we handle categorical variables in Machine Learning? What are the common techniques?**\n",
        "- In machine learning, we need to convert categorical variables (like colors or names) into numbers because most algorithms can only work with numerical data. To do this, we use techniques like label encoding, which assigns each category a number, and one-hot encoding, which creates separate columns for each category with 0s and 1s. For ordered categories, we can use ordinal encoding, and for more advanced cases, we might use target encoding or frequency encoding. These methods help the model understand and use categorical data correctly during training."
      ],
      "metadata": {
        "id": "gQEseErwT-Xl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What do you mean by training and testing a dataset?**\n",
        "- Training a dataset means using part of the data to teach a machine learning model how to make predictions by learning patterns from it. Testing a dataset means using a different part of the data to check if the model can make accurate predictions on new, unseen information. This helps us know if the model has learned well and can work properly in real situations."
      ],
      "metadata": {
        "id": "KC98dIG3URy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is sklearn.preprocessing?**\n",
        "- sklearn.preprocessing is a part of the popular Python library scikit-learn that helps prepare data before using it in machine learning models. It includes tools to change or scale data so that the model can learn better and faster. For example, it can normalize numbers, convert categories into numbers, or handle missing values. In simple terms, it helps clean and get our data ready for machine learning."
      ],
      "metadata": {
        "id": "qSQyw1FjUg-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. What is a Test set?**\n",
        "- A test set is a portion of a dataset that is kept separate from the data used to train a machine learning model. After the model learns from the training data, the test set is used to check how well the model performs on new, unseen data. It helps us see if the model can make accurate predictions in real-life situations and avoid mistakes like overfitting."
      ],
      "metadata": {
        "id": "tOnpY2P0VPCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11.How do we split data for model fitting (training and testing) in Python?**\n",
        "- In Python, we split data into training and testing sets using a tool called train_test_split from the scikit-learn library. This function randomly divides our data so that part of it is used to teach the model (training set) and the other part is used to check how well the model works (testing set). We can decide what percentage goes to each set, like 80% for training and 20% for testing. This helps make sure the model learns well and can also be tested fairly on new data.\n"
      ],
      "metadata": {
        "id": "JUN9RWQtVYnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12.How do we approach a Machine Learning problem?**\n",
        "- To approach a machine learning problem, we first understand the goal and gather the right data. Then, we can clean and prepare the data by handling missing values and converting categories into numbers. Next, we choose a suitable model and train it using part of the data. After that, we will test the model on new data to see how well it works. Finally, we have to evaluate the results, make improvements if needed, and use the model to make predictions or decisions."
      ],
      "metadata": {
        "id": "hIyS8ql8bwIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Why do we have to perform EDA before fitting a model to the data?**\n",
        "- We perform Exploratory Data Analysis (EDA) before fitting a model to understand the data better. EDA helps us find patterns, spot mistakes or missing values, and see how different variables relate to each other. This helps us choose the right model and prepare the data properly, which leads to better and more accurate results when we train the model."
      ],
      "metadata": {
        "id": "SwE4RFf2V-uP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14.How can you find correlation between variables in Python?**\n",
        "- In Python, we can find the correlation between variables easily using the pandas library. After putting our data into a table called a DataFrame, we can use the .corr() function to calculate how strongly the variables are related. This function gives us numbers between -1 and 1, where values close to 1 mean a strong positive connection, close to -1 mean a strong negative connection, and near 0 means little or no connection. It helps us quickly understand relationships in our data."
      ],
      "metadata": {
        "id": "RviJNE9oXLrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. What is causation? Explain difference between correlation and causation with an example.**\n",
        "- Causation means that one thing directly causes another to happen. For example, if we water a plant, it grows — watering causes growth. The difference between correlation and causation is that correlation just shows that two things happen together, but one does not necessarily cause the other. For example, ice cream sales and swimming pool visits might both go up at the same time (correlation), but buying ice cream doesn’t cause people to swim — the hot weather causes both. So, correlation means two things are related, while causation means one actually makes the other happen."
      ],
      "metadata": {
        "id": "gaAlmIKSX_nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. What is an Optimizer? What are different types of optimizers? Explain each with an example.**\n",
        "- An optimizer is a tool used in machine learning to help a model learn by adjusting its settings (called parameters) to reduce errors and improve accuracy. It works by minimizing a function called the loss, which measures how wrong the model’s predictions are. There are different types of optimizers, such as:\n",
        "\n",
        " **Gradient Descent:** The most basic optimizer that changes parameters step-by-step in the direction that reduces the error.\n",
        "\n",
        " **Stochastic Gradient Descent (SGD):** Similar to gradient descent but updates parameters using small random samples of data, making it faster for big datasets.\n",
        "\n",
        " **Adam:** A popular optimizer that combines ideas from other methods and adapts the learning rate automatically, often leading to faster and better learning.\n",
        "\n",
        "For example, Adam is widely used because it helps models learn efficiently without needing much manual tuning."
      ],
      "metadata": {
        "id": "kkbclg4lYTc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. What is sklearn.linear_model ?**\n",
        "- sklearn.linear_model is a part of the scikit-learn library in Python that provides tools to build linear models for machine learning. These models predict a target variable based on one or more input features by finding the best straight-line (or plane) fit through the data. It includes popular methods like Linear Regression for continuous outcomes and Logistic Regression for classification problems. In simple terms, sklearn.linear_model helps us to create models that find relationships between variables using simple math equations."
      ],
      "metadata": {
        "id": "P7qdKOr_Yp4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. What does model.fit() do? What arguments must be given?**\n",
        "- The model.fit() function trains a machine learning model by showing it the data so it can learn patterns. We need to give it two things: the input features (called X) and the correct answers or labels (called y). This way, the model knows what to learn from the data and how to make predictions later."
      ],
      "metadata": {
        "id": "zwxBxjXPY2ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. What does model.predict() do? What arguments must be given?**\n",
        "- The model.predict() function is used to make predictions with a trained machine learning model. We give it new input data (features), and it returns the model’s guess or output based on what it learned during training. The main argument we need to provide is the input data (X) for which we want predictions."
      ],
      "metadata": {
        "id": "wpCwIAvdZPsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. What is feature scaling? How does it help in Machine Learning?**\n",
        "- Feature scaling means adjusting the values of different features in our data so they are all on a similar scale, like between 0 and 1 or having an average of zero. This is important because many machine learning models work better and learn faster when features have similar ranges. Without scaling, features with bigger numbers can unfairly influence the model, causing it to perform poorly. So, feature scaling helps make the learning process smoother and more accurate."
      ],
      "metadata": {
        "id": "gsapf7i4Zc5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. How do we perform scaling in Python?**\n",
        "- In Python, we perform feature scaling easily using tools from the scikit-learn library, like StandardScaler or MinMaxScaler. We have to first create a scaler object, then use its fit_transform() method on our training data to scale the features. This changes the data to the desired scale, like making the average zero or values between 0 and 1. Later, we can use the same scaler to transform new data before making predictions. This helps our machine learning model work better and faster."
      ],
      "metadata": {
        "id": "O3rdoB19Z1fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22. Explain data encoding?**\n",
        "- Data encoding means converting data, especially non-numerical data like categories or text, into numbers that a machine learning model can understand. Since models work with numbers, encoding helps turn things like colors, names, or labels into numeric values. Common methods include label encoding (assigning a number to each category) and one-hot encoding (creating separate columns for each category with 0s and 1s). Encoding helps the model use all types of data correctly."
      ],
      "metadata": {
        "id": "3uUzXy6iaC1p"
      }
    }
  ]
}